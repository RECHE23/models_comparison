{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the effect of using different loss functions (ReLU) - Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"960\"\n",
       "            height=\"540\"\n",
       "            src=\"https://www.youtube.com/embed/4W7To-yFGas\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x10d7ec2b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('4W7To-yFGas', width=960, height=540)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the effect of using different loss functions (ReLU) - Batches of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"960\"\n",
       "            height=\"540\"\n",
       "            src=\"https://www.youtube.com/embed/A6YMVZ-SQwc\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x10d85ea60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo('A6YMVZ-SQwc', width=960, height=540)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to the parent path:\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Import the helper scripts:\n",
    "from utils import *\n",
    "from LinearLoss import LinearLoss\n",
    "\n",
    "# Name of the experiment:\n",
    "name=\"loss_functions_relu\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a two moons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons, y_moons = sklearn.datasets.make_moons(150, noise=0.25, random_state=0)\n",
    "y_moons = np.where(y_moons==0, -1., y_moons)\n",
    "plt.scatter(X_moons[:,0], X_moons[:,1], s=40, c=y_moons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a two blobs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_blobs, y_blobs = sklearn.datasets.make_blobs(n_samples=150, centers=2, n_features=2, random_state=0)\n",
    "y_blobs = np.where(y_blobs==0, -1., y_blobs)\n",
    "plt.scatter(X_blobs[:,0], X_blobs[:,1], s=40, c=y_blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a concentric circles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_circles, y_circles = sklearn.datasets.make_circles(n_samples=150, noise=0.09, random_state=0)\n",
    "y_circles = np.where(y_circles==0, -1., y_circles)\n",
    "plt.scatter(X_circles[:,0], X_circles[:,1], s=40, c=y_circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert SKLearn datasets into PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moons_dataset = convert_to_pytorch_dataset(X_moons, y_moons)\n",
    "blobs_dataset = convert_to_pytorch_dataset(X_blobs, y_blobs)\n",
    "circles_dataset = convert_to_pytorch_dataset(X_circles, y_circles)\n",
    "\n",
    "datasets = [moons_dataset, blobs_dataset, circles_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Rectified Linear Unit (ReLU) based neural network:\n",
    "class ReLUNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ReLUNet, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Flatten(),\n",
    "                                    nn.Linear(input_size, 32),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(32, 32),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(32, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.erf(self.layers(x))\n",
    "\n",
    "# Selected models are initialized for every dataset:\n",
    "models = [{\n",
    "    'ReLU Linear loss': ReLUNet(2),\n",
    "    'ReLU L1 loss': ReLUNet(2),\n",
    "    'ReLU Smooth L1 loss': ReLUNet(2),\n",
    "    'ReLU MSE loss': ReLUNet(2),\n",
    "    'ReLU BCE loss': ReLUNet(2)\n",
    "          } for _ in datasets]\n",
    "\n",
    "# Initialise all networks with the same weights and biases:\n",
    "state = next(iter(models[0].values())).state_dict()\n",
    "for d, _ in enumerate(datasets):\n",
    "    for m in models[d].values():\n",
    "        m.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01    # Learning rate\n",
    "mm = 0.9     # Momentum\n",
    "wd = 0.001   # Weight decay\n",
    "\n",
    "optimizers = [dict((k, torch.optim.SGD(model.parameters(), lr=lr, momentum=mm, weight_decay=wd))\n",
    "                   for k, model in models[i].items()) for i in range(len(datasets))]\n",
    "\n",
    "# Loss function:\n",
    "criterion = {\n",
    "    'ReLU Linear loss': LinearLoss(),\n",
    "    'ReLU L1 loss': nn.L1Loss(),\n",
    "    'ReLU Smooth L1 loss': nn.SmoothL1Loss(),\n",
    "    'ReLU MSE loss': nn.MSELoss(),\n",
    "    'ReLU BCE loss': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "\n",
    "# Number of epochs:\n",
    "epochs = 300\n",
    "\n",
    "# Sampling method:\n",
    "batch_size=32\n",
    "shuffle=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates the animated plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_animated_plot(epochs=epochs, \n",
    "                       datasets=datasets, \n",
    "                       models=models, \n",
    "                       optimizers=optimizers, \n",
    "                       criterion=criterion, \n",
    "                       filename=name, \n",
    "                       batch_size=batch_size, \n",
    "                       shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
